#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üìä –ê–ù–ê–õ–ò–ó–ê–¢–û–† –î–ê–ù–ù–´–• SHUKABASE

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É HTML-—Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ cleaned_vedabase
–∏ –≤—ã–≤–æ–¥–∏—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.

–ó–ê–ü–£–°–ö:
    python rag/analyze_data.py
"""

import os
from pathlib import Path
from collections import defaultdict

def analyze_html_files():
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É HTML —Ñ–∞–π–ª–æ–≤ –≤ cleaned_vedabase
    """
    print("="*70)
    print("üìö –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–• SHUKABASE")
    print("="*70)
    print()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞–ø–∫–∏
    data_dir = Path("cleaned_vedabase")
    
    if not data_dir.exists():
        print("‚ùå –û–®–ò–ë–ö–ê: –ü–∞–ø–∫–∞ 'cleaned_vedabase' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        print("‚ÄºÔ∏è  –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –∑–∞–ø—É—Å–∫–∞–µ—Ç–µ —Å–∫—Ä–∏–ø—Ç –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏ SHUKABASE")
        return
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä—É—Å—Å–∫–∏–µ –∫–Ω–∏–≥–∏
    ru_dir = data_dir / "ru"
    en_dir = data_dir / "en"
    
    for lang, lang_name in [(ru_dir, "–†—É—Å—Å–∫–∏–µ"), (en_dir, "–ê–Ω–≥–ª–∏–π—Å–∫–∏–µ")]:
        if not lang.exists():
            print(f"‚ö†Ô∏è  –ü–∞–ø–∫–∞ {lang} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º...")
            continue
            
        print(f"üìö {lang_name} –ø–∏—Å–∞–Ω–∏—è:")
        print("-" * 70)
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–Ω–∏–≥–∞–º
        books = defaultdict(int)
        html_files = list(lang.rglob("*.html"))
        
        for html_file in html_files:
            try:
                parts = html_file.relative_to(lang).parts
                if len(parts) > 0:
                    book_code = parts[0]
                    books[book_code] += 1
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {html_file}: {e}")
        
        if not books:
            print("  üö´ –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        else:
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–Ω–∏–≥–∏ –ø–æ –∫–æ–¥—É
            for book_code in sorted(books.keys()):
                count = books[book_code]
                print(f"  üìñ {book_code:15s} - {count:5d} —Ñ–∞–π–ª–æ–≤")
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_files = len(html_files)
        print()
        print(f"  üìä –í—Å–µ–≥–æ –∫–Ω–∏–≥: {len(books)}")
        print(f"  üìÑ –í—Å–µ–≥–æ HTML —Ñ–∞–π–ª–æ–≤: {total_files:,}")
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä–Ω—ã–π —Ä–∞–∑–º–µ—Ä
        total_size = 0
        for html_file in html_files:
            try:
                total_size += html_file.stat().st_size
            except:
                pass
        
        size_mb = total_size / (1024 * 1024)
        print(f"  üíæ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {size_mb:.2f} –ú–ë")
        print()
    
    print("="*70)
    print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω!")
    print("="*70)
    print()
    print("üëâ –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: –∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø–∞—Ä—Å–µ—Ä –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞")
    print("   python rag/run_parser_locally.py")
    print()

if __name__ == "__main__":
    try:
        analyze_html_files()
    except Exception as e:
        print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()