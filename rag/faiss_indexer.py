#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üîç –°–û–ó–î–ê–ù–ò–ï –ò–ù–î–ï–ö–°–ê FAISS –î–õ–Ø –ë–´–°–¢–†–û–ì–û –ü–û–ò–°–ö–ê

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Å–æ–∑–¥–∞–µ—Ç –∏–Ω–¥–µ–∫—Å FAISS –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
–ø–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º —á–∞–Ω–∫–æ–≤.

–ó–ê–ü–£–°–ö:
    python rag/faiss_indexer.py
"""

import json
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Any
import time

try:
    import faiss
except ImportError:
    print("‚ö†Ô∏è  FAISS –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Å –ø–æ–º–æ—â—å—é:")
    print("   pip install faiss-cpu  (–∏–ª–∏ faiss-gpu –¥–ª—è GPU)")
    exit(1)


class FAISSIndexer:
    def __init__(self, embedding_dim: int = 768): # –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è text-embedding-004
        """
        Args:
            embedding_dim: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        """
        self.embedding_dim = embedding_dim
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º IVFFlat –¥–ª—è –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (nlist) –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–¥–æ–±—Ä–∞–Ω–æ –¥–ª—è –≤–∞—à–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        self.quantizer = faiss.IndexFlatL2(embedding_dim)
        self.index = faiss.IndexIVFFlat(self.quantizer, embedding_dim, 100) # 100 - —Ä–∞–∑—É–º–Ω–æ–µ —á–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        self.index.nprobe = 10 # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–∏–∂–∞–π—à–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
    
    def load_embeddings(self, language: str = 'ru') -> Tuple[np.ndarray, Dict]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ .npz —Ñ–∞–π–ª–∞
        
        Args:
            language: 'ru' –∏–ª–∏ 'en'
            
        Returns:
            (embeddings_matrix, metadata)
        """
        metadata_file = f"rag/embeddings_metadata_{language}.json"
        npz_file = f"rag/embeddings_{language}.npz" # –ò–∑–º–µ–Ω–µ–Ω–æ –Ω–∞ .npz
        
        print(f"üìÇ –ó–∞–≥—Ä—É–∂–∞—é —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ {npz_file}...")
        if not Path(npz_file).exists():
            print(f"‚ö†Ô∏è  –§–∞–π–ª {npz_file} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–ø—É—Å–∫–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É {language}.")
            return None, None
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ NPZ —Ñ–∞–π–ª–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        npz_data = np.load(npz_file)
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –º–∞—Å—Å–∏–≤—ã –∏–∑ npz –≤ –æ–¥–∏–Ω
        embeddings_list = [npz_data[key] for key in sorted(npz_data.files) if key.startswith('embeddings_')]
        
        if not embeddings_list:
            print(f"‚ùå –í —Ñ–∞–π–ª–µ {npz_file} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –º–∞—Å—Å–∏–≤–æ–≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤. –ü—Ä–æ–ø—É—Å–∫–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É {language}.")
            return None, None
            
        embeddings = np.vstack(embeddings_list).astype('float32')
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {embeddings.shape[0]:,} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ {embeddings.shape[1]}")
        
        if not Path(metadata_file).exists():
            print(f"‚ö†Ô∏è  –§–∞–π–ª {metadata_file} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–ø—É—Å–∫–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É {language}.")
            return None, None
            
        with open(metadata_file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
            
        return embeddings, metadata
        
    def build_index(self, embeddings: np.ndarray) -> faiss.Index:
        """
        –°—Ç—Ä–æ–∏—Ç FAISS –∏–Ω–¥–µ–∫—Å –∏–∑ –º–∞—Å—Å–∏–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.
        
        Args:
            embeddings: –º–∞—Å—Å–∏–≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            
        Returns:
            –ü–æ—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π FAISS –∏–Ω–¥–µ–∫—Å
        """
        print(f"\nüî® –°—Ç—Ä–æ—é FAISS –∏–Ω–¥–µ–∫—Å –¥–ª—è {embeddings.shape[0]:,} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
        start_time = time.time()
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –≤ –∏–Ω–¥–µ–∫—Å
        faiss.normalize_L2(embeddings)
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–∏–ø –∏–Ω–¥–µ–∫—Å–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        # IndexFlatL2 - –ø—Ä–æ—Å—Ç–æ–π, –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        # IndexIVFFlat - –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π, –¥–ª—è –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö, —Ç—Ä–µ–±—É–µ—Ç –æ–±—É—á–µ–Ω–∏—è
        if embeddings.shape[0] < 10000: # –ú–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–æ—Ä–æ–≥
            index = faiss.IndexFlatL2(self.embedding_dim)
            print(f"  üìç –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è IndexFlatL2")
            index.add(embeddings)
        else:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è IndexIVFFlat —Ç—Ä–µ–±—É–µ—Ç –æ–±—É—á–µ–Ω–∏—è
            quantizer = faiss.IndexFlatL2(self.embedding_dim)
            nlist = min(100, int(np.sqrt(embeddings.shape[0]))) # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
            index = faiss.IndexIVFFlat(quantizer, self.embedding_dim, nlist, faiss.METRIC_L2)
            index.nprobe = min(50, nlist) # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
            print(f"  üìç –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è IndexIVFFlat —Å {nlist} –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏, nprobe={index.nprobe}")
            
            # –û–±—É—á–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
            if not index.is_trained:
                print("  ‚öôÔ∏è –û–±—É—á–∞—é IndexIVFFlat (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è)...")
                index.train(embeddings)
                print("  ‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
            
            index.add(embeddings)
        
        elapsed = time.time() - start_time
        print(f"‚úÖ –ò–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω –∑–∞ {elapsed:.1f} —Å–µ–∫")
        return index
    
    def save_index(self, index: faiss.Index, metadata: Dict, language: str = 'ru'):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç FAISS –∏–Ω–¥–µ–∫—Å –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª—ã.
        """
        index_file = f"rag/faiss_index_{language}.bin"
        metadata_file = f"rag/faiss_metadata_{language}.json"
        
        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω—è—é –∏–Ω–¥–µ–∫—Å –≤ {index_file}...")
        faiss.write_index(index, index_file)
        index_size = Path(index_file).stat().st_size / (1024*1024)
        print(f"‚úÖ –ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {index_size:.2f} –ú–ë")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–Ω–¥–µ–∫—Å–∞
        metadata['embedding_model'] = "models/text-embedding-004"
        metadata['embedding_dim'] = self.embedding_dim

        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        metadata_size = Path(metadata_file).stat().st_size / (1024*1024)
        print(f"‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metadata_size:.2f} –ú–ë")
        return index_file, metadata_file

    def process_language(self, language: str = 'ru') -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ —è–∑—ã–∫–∞.
        """
        index_file = f"rag/faiss_index_{language}.bin"
        metadata_file_out = f"rag/faiss_metadata_{language}.json"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∏–Ω–¥–µ–∫—Å –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        if Path(index_file).exists() and Path(metadata_file_out).exists():
            index_size = Path(index_file).stat().st_size / (1024*1024)
            print(f"‚è© –ò–Ω–¥–µ–∫—Å –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è {language} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç ({index_size:.2f} –ú–ë). –ü—Ä–æ–ø—É—Å–∫–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É.")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, —á—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å –∏—Ö –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            with open(metadata_file_out, 'r', encoding='utf-8') as f:
                existing_metadata = json.load(f)
            
            return {
                'language': language,
                'total_embeddings': existing_metadata.get('total_embeddings', 'N/A'),
                'embedding_dim': existing_metadata.get('embedding_dim', self.embedding_dim),
                'index_file': index_file,
                'metadata_file': metadata_file_out
            }

        embeddings, metadata = self.load_embeddings(language)
        
        if embeddings is None or metadata is None:
            return None

        index = self.build_index(embeddings)
        index_file, metadata_file = self.save_index(index, metadata, language)
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Å—é–¥–∞)
        # self.test_search(index, embeddings, metadata, language)
        
        stats = {
            'language': language,
            'total_embeddings': embeddings.shape[0],
            'embedding_dim': embeddings.shape[1],
            'index_file': index_file,
            'metadata_file': metadata_file
        }
        return stats


def process_all_languages():
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –æ–±–æ–∏—Ö —è–∑—ã–∫–æ–≤."""
    
    print("="*70)
    print("üîç –°–û–ó–î–ê–ù–ò–ï FAISS –ò–ù–î–ï–ö–°–û–í")
    print("="*70)
    
    indexer = FAISSIndexer(embedding_dim=768) # –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
    
    all_stats = {}
    
    print("\nüìç –≠–¢–ê–ü 1: –ò–ù–î–ï–ö–° –î–õ–Ø –†–£–°–°–ö–ò–• –ü–ò–°–ê–ù–ò–ô")
    print("-" * 70)
    stats_ru = indexer.process_language('ru')
    if stats_ru:
        all_stats['ru'] = stats_ru
    
    print("\nüìç –≠–¢–ê–ü 2: –ò–ù–î–ï–ö–° –î–õ–Ø –ê–ù–ì–õ–ò–ô–°–ö–ò–• –ü–ò–°–ê–ù–ò–ô")
    print("-" * 70)
    stats_en = indexer.process_language('en')
    if stats_en:
        all_stats['en'] = stats_en
    
    print("\n" + "="*70)
    if not all_stats:
        print("‚ùå –ò–ù–î–ï–ö–°–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ò–õ–û–°–¨ –° –û–®–ò–ë–ö–ê–ú–ò –ò–õ–ò –ë–ï–ó –°–û–ó–î–ê–ù–ò–Ø –ò–ù–î–ï–ö–°–û–í.")
    else:
        print("‚úÖ –ò–ù–î–ï–ö–°–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print("="*70)
    
    for lang, stats in all_stats.items():
        print(f"\nüìä {lang.upper()}:")
        if stats:
            print(f"   üî¢ –í—Å–µ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {stats['total_embeddings']:,}")
            print(f"   üìè –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {stats['embedding_dim']}")
            print(f"   üìö –ò–Ω–¥–µ–∫—Å: {stats['index_file']}")
            print(f"   üìù –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {stats['metadata_file']}")
        else:
            print("   ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ (–≤–µ—Ä–æ—è—Ç–Ω–æ, –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏).")
    
    if all_stats:
        print("\n‚ú® RAG —Å–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
        print("üëâ –¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å API —Å–µ—Ä–≤–µ—Ä: python rag/rag_api_server.py")
    
    return all_stats


if __name__ == "__main__":
    process_all_languages()
